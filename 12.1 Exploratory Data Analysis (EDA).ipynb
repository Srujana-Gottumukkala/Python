{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65df617b",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis\n",
    "    Process to create clean data to further build predictive models\n",
    "    Sometimes, also referred to as feature engineering\n",
    "    Seven techniques of EDA - \n",
    "        1. Variable Identification\n",
    "        2. Univariate Analysis\n",
    "        3. Bivariate Analysis - correlation\n",
    "        4. Outlier treatment\n",
    "        5. Missing value treatment (for numerical and categorical)\n",
    "        6. Variable transformation (also called transformer)\n",
    "        7. Variable creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6127af3",
   "metadata": {},
   "source": [
    "### ETL - Extract, Transform, Load\n",
    "\n",
    "   - Eg of where ETL tools are required - The data from stores like DMart (they contain **local servers**), etc. are loaded into a **master db/master server**, (for instance, such contracts maybe taken up by service companies to extract, transform and load the data - say once every 24 hours, say during downtime onto the master db). **Datawarehousing** teams work on this.\n",
    "   - At a later stage, Data Analysts come into picture to convert raw data to clean data. EDA techniques are required at this stage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ec3d54",
   "metadata": {},
   "source": [
    "Data Analysts work on structured data, whereas data engineers work on unstructured data - for example live cricket match telecast.\n",
    "Data Engineer works on Hadoop, PySpark, etc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b903f98e",
   "metadata": {},
   "source": [
    "### 1. Variable Identification\n",
    "    - Variables are present in the form of columns\n",
    "    - Variables are nothing but attributes/ features\n",
    "    - Dependent variables - called as target attribute, labelled attribute, predictive, usually denoted by 'y'\n",
    "    - Independent variables - called as non-target attribute, non-labelled attribute, non-predictive attribute, usually denoted by 'x'\n",
    "        y = x1 + x2 + x3\n",
    "        y = m1x1 + m2x2 + m3x3 (Multiple linear regression algorithm)\n",
    "        y = mx + c (Simple linear regression)\n",
    "    - Relevant vs irrelevant attributes. If irrelevant attributes are present, then overfitting problem/multicollinearity arises in machine learning models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3851bf",
   "metadata": {},
   "source": [
    "### Machine Learning \n",
    "     - Regression - If dependent variable is continuous\n",
    "              - Simple linear regression\n",
    "              - Multiple linear regression\n",
    "              - Polynomial regression\n",
    "              - Support vector regression\n",
    "              - K nearest neightbour regression algorithm\n",
    "              - Decision tree\n",
    "              - Random forest\n",
    "              - XGBoost regression\n",
    "              - LGBM regression\n",
    "              - ANN regression\n",
    "              - Time series\n",
    "     - Classification - If dependent variable is binary or categorical\n",
    "              - Binary - Cricket match win/lose (1/0)\n",
    "                       - Spam/Non-spam email\n",
    "                       - Positive review/Negative review\n",
    "                       - Pass/Fail\n",
    "                       - Profit/Loss\n",
    "                       - Yes/No\n",
    "                       - Hot/Cold\n",
    "                       - High/Low\n",
    "              - Classification\n",
    "                       - Logistic regression\n",
    "                       - SVM classifier\n",
    "                       - KNN classifier\n",
    "                       - Decision Tree\n",
    "                       - Ensemble Learning\n",
    "                       - XGBoost\n",
    "                       - Naive Bayes\n",
    "                       - ANN Classifier\n",
    "                       - LGBM Classifier/ LGBM Model\n",
    "     - Clustering - No dependent varibale, but if the variable is discrete"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb8ef51",
   "metadata": {},
   "source": [
    "**Note:** Sometimes at a stage of analysis, a particular regression model may be more relevant. Whereas, at another stage, a different  model may be applicable. For example, house price can be a dependent variable with several different independent variables. At this stage, regression can be used. But at a later stage, when the model turns to our decision of purchase - yes/no, the model becomes classification algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d2b0ab",
   "metadata": {},
   "source": [
    "### 2. Univariate Analysis\n",
    "    Plot the graph using one variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51137a5d",
   "metadata": {},
   "source": [
    "### 3. Plot the graph using two variables\n",
    "    Correlation - relation among two attributes\n",
    "    Range of the correlation: -1 to 1\n",
    "    Positive correlation range: 0 to 1 \n",
    "    Negative correlation range: -1 to 0 \n",
    "    No correlation: 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ff4541",
   "metadata": {},
   "source": [
    "### 4. Outlier treatment\n",
    "    Also called as anomaly detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe136ecd",
   "metadata": {},
   "source": [
    "### 5. Missing value treatment\n",
    "    Intervieew questions - how do you treat missing values\n",
    "    If numerical data is missing, you can replace the missing values with mean, median, mode strategy\n",
    "    If categorical data is missing, you can replace with mode. If the data does not contain a mode, then use the neighbouring attributes (KNN strategy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77bea2bc",
   "metadata": {},
   "source": [
    "### 6. Variable transformer / Variable imputation techniques\n",
    "       - To convert categorical data to numerical data to build machine learning predictive models\n",
    "        1. Dummy variable\n",
    "        2. One hot encoder\n",
    "        3. Label encoder\n",
    "        \n",
    "        to import, use:\n",
    "        from sklearn.preprocessing import labelencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187de7f1",
   "metadata": {},
   "source": [
    "### 7. Variable Creation\n",
    "        From one categorical varibale, create more variables using transformers/ imputation technique"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
